# ==============================================================================
# æ–‡ä»¶å: utils/data_repro_pipeline.py
# ç‰ˆæœ¬: v2 (Strict Split & Augmentation)
# æ”¹è¿›:
#   1. ä¸¥æ ¼çš„æ•°æ®åˆ’åˆ† (æŒ‰æ–‡ä»¶åé¡ºåºåˆ‡åˆ†ï¼Œé¿å…æ—¶åºæ•°æ®æ³„éœ²)ã€‚
#   2. è®­ç»ƒé›†åŠ å…¥å®æ—¶æ•°æ®å¢å¼º (æ°´å¹³ç¿»è½¬)ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆã€‚
#   3. ä¿®å¤äº†è™šé«˜è¯„ä¼°çš„æ•°æ®æºé—®é¢˜ã€‚
# ==============================================================================

import tensorflow as tf
import os
import glob
import numpy as np
import cv2
from tensorflow.keras.applications.vgg19 import preprocess_input


class AcademicDataGenerator:
    def __init__(self, target='train', batch_size=1, width=1280, height=384,
                 data_dir='data/training'):
        self.target = target
        self.batch_size = batch_size
        self.width = width
        self.height = height

        # è·¯å¾„é…ç½®
        if target == 'test':
            self.image_dir = 'data/testing/image_2'
            self.adi_dir = 'data/testing/ADI'
            self.img_paths = sorted(glob.glob(os.path.join(self.image_dir, '*')))
            self.adi_paths = sorted(glob.glob(os.path.join(self.adi_dir, '*')))
            self.mask_paths = []
        else:
            self.image_dir = os.path.join(data_dir, 'image_2')
            self.adi_dir = os.path.join(data_dir, 'ADI')
            self.mask_dir = os.path.join(data_dir, 'gt_image_2')

            # 1. è·å–æ‰€æœ‰æœ‰æ•ˆçš„é…å¯¹æ–‡ä»¶
            mask_files = sorted(glob.glob(os.path.join(self.mask_dir, '*_road_*.png')))

            all_img_paths = []
            all_adi_paths = []
            all_mask_paths = []

            for m_path in mask_files:
                basename = os.path.basename(m_path)
                parts = basename.split('_')
                # å…¼å®¹ KITTI æ ¼å¼: um_road_000000.png -> um_000000.png
                # æ³¨æ„ï¼šæœ‰äº›æ–‡ä»¶åå¯èƒ½æ˜¯ uu_road_000000.png -> uu_000000.png
                img_name = parts[0] + '_' + parts[2]

                img_p = os.path.join(self.image_dir, img_name)
                adi_p = os.path.join(self.adi_dir, img_name)

                if os.path.exists(img_p) and os.path.exists(adi_p):
                    all_img_paths.append(img_p)
                    all_adi_paths.append(adi_p)
                    all_mask_paths.append(m_path)

            # 2. ä¸¥æ ¼åˆ’åˆ† (Strict Split)
            # ä¸ä½¿ç”¨éšæœº Shuffleï¼Œè€Œæ˜¯æŒ‰é¡ºåºæˆªæ–­ã€‚
            # KITTI æ•°æ®é›†é€šå¸¸ ID ç›¸é‚»çš„å›¾ç‰‡ç›¸ä¼¼åº¦é«˜ã€‚
            # æˆ‘ä»¬å–å‰ 80% åšè®­ç»ƒï¼Œå 20% åšéªŒè¯ã€‚
            total_samples = len(all_img_paths)
            split_idx = int(total_samples * 0.8)

            if target == 'train':
                self.img_paths = all_img_paths[:split_idx]
                self.adi_paths = all_adi_paths[:split_idx]
                self.mask_paths = all_mask_paths[:split_idx]
                print(f"ğŸ“˜ Training Set: {len(self.img_paths)} samples (First 80%)")
            else:
                self.img_paths = all_img_paths[split_idx:]
                self.adi_paths = all_adi_paths[split_idx:]
                self.mask_paths = all_mask_paths[split_idx:]
                print(f"ğŸ“™ Validation Set: {len(self.img_paths)} samples (Last 20%)")

    def _sharpen_adi(self, adi_img):
        """å¤ç°è®ºæ–‡ Eq. 18: ADI é”åŒ–"""
        kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])
        adi_sharp = cv2.filter2D(adi_img, -1, kernel)
        adi_sharp = cv2.filter2D(adi_sharp, -1, kernel)
        return adi_sharp

    def _read_data(self, img_path, adi_path, mask_path):
        # 1. RGB Image
        img = cv2.imread(img_path.decode('utf-8'))
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, (self.width, self.height))
        # è®­ç»ƒæ—¶å¯ä»¥åœ¨è¿™é‡ŒåŠ  Augmentationï¼Œä½†ä¸ºäº† CPU æ•ˆç‡ï¼Œæˆ‘ä»¬ç§»åˆ° TF graph é‡Œåšç®€å•çš„ Flip
        img = preprocess_input(img)

        # 2. ADI Image
        adi = cv2.imread(adi_path.decode('utf-8'))
        adi = cv2.resize(adi, (self.width, self.height))
        adi = self._sharpen_adi(adi)
        adi = adi.astype(np.float32) / 255.0
        if np.any(adi > 0):
            adi = adi - np.mean(adi[adi > 0])

        # 3. Mask
        mask = cv2.imread(mask_path.decode('utf-8'))
        mask = cv2.resize(mask, (self.width, self.height), interpolation=cv2.INTER_NEAREST)
        mask = mask[:, :, 2]
        mask = (mask > 0).astype(np.float32)
        mask = np.expand_dims(mask, axis=-1)

        return img, adi, mask

    def _tf_map_wrapper(self, img_path, adi_path, mask_path):
        img, adi, mask = tf.numpy_function(
            self._read_data,
            [img_path, adi_path, mask_path],
            [tf.float32, tf.float32, tf.float32]
        )
        img.set_shape([self.height, self.width, 3])
        adi.set_shape([self.height, self.width, 3])
        mask.set_shape([self.height, self.width, 1])

        # ==== åœ¨çº¿æ•°æ®å¢å¼º (Data Augmentation) ====
        # ä»…é’ˆå¯¹è®­ç»ƒé›† (é€šè¿‡åˆ¤æ–­ self.target)
        if self.target == 'train':
            # éšæœºæ°´å¹³ç¿»è½¬ (æ¦‚ç‡ 50%)
            # æ³¨æ„ï¼šImage, ADI, Mask å¿…é¡»åŒæ—¶ç¿»è½¬ï¼
            if tf.random.uniform(()) > 0.5:
                img = tf.image.flip_left_right(img)
                adi = tf.image.flip_left_right(adi)
                mask = tf.image.flip_left_right(mask)

            # è¿˜å¯ä»¥åŠ ä¸€ç‚¹äº®åº¦å’Œå¯¹æ¯”åº¦å¢å¼º (ä»…å¯¹ Image)
            img = tf.image.random_brightness(img, max_delta=0.1)
            # æ³¨æ„ï¼šVGG preprocess åæ•°å€¼èŒƒå›´å˜äº†ï¼Œbrightness éœ€è¦å°å¿ƒï¼Œè¿™é‡Œä¿å®ˆä¸€ç‚¹å…ˆä¸åŠ é¢œè‰²å˜æ¢

        return (img, adi), mask

    def get_dataset(self):
        dataset = tf.data.Dataset.from_tensor_slices((self.img_paths, self.adi_paths, self.mask_paths))

        if self.target == 'train':
            dataset = dataset.shuffle(buffer_size=len(self.img_paths))  # å…¨é‡ Shuffle ç´¢å¼•ï¼Œä½†ä¸ Shuffle éªŒè¯é›†

        dataset = dataset.map(self._tf_map_wrapper, num_parallel_calls=tf.data.AUTOTUNE)
        dataset = dataset.batch(self.batch_size)
        dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)
        return dataset

    def __len__(self):
        return len(self.img_paths) // self.batch_size
